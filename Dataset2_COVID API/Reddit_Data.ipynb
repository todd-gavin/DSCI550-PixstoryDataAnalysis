{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from psaw import PushshiftAPI                               #Importing wrapper library for reddit(Pushshift)\n",
    "import datetime as dt                                       #Importing library for date management\n",
    "import pandas as pd                                         #Importing library for data manipulation in python\n",
    "import matplotlib.pyplot as plt      \n",
    "import yfinance as yf                    #Importing library for creating interactive visualizations in Python\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import statsmodels.formula.api as smf\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Data Collecton Plan\n",
    "\n",
    "For posts from 1/1/2020 to 12/31/2022, retrieve data on:\n",
    "\n",
    "- (1) The most popular post from that day. Get the following data:\n",
    "    - topic on subreddit it belongs to \n",
    "    - text of post \n",
    "    - title of post\n",
    "    - score of post\n",
    "- (2) Number of posts in a subreddit for that Day (sports, mental health, or science)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plan:\n",
    "\n",
    "1. Create a function \"def_popular_post_data(date)\" that retrieves all data attributes of a post given the date it was posted \n",
    "2. Create a function \"get_each_popular_post(start date, end date)\" that inputs a start date and end date, loops through each day and inputs it into the \"def_popular_post_data(date)\" function, and returns a list of dictionaries, with each element being the output of the \"def_popular_post_data(date)\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = int(dt.datetime(2021,2,26,0,0).timestamp()) #.timestamp() converts the date to epoch time \n",
    "start_date = int(dt.datetime(2021,1,1,0,0).timestamp())\n",
    "subreddit = 'learnpython'\n",
    "\n",
    "test_day = int(dt.datetime(2021,2,26,0,0).timestamp())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_most_popular_post_on_date(timestamp):\n",
    "    \n",
    "    # Make API request to get most popular post on date\n",
    "    # url1 = f\"https://api.pushshift.io/reddit/search/submission/?after={timestamp}&before={timestamp+86400}&sort_type=score&sort=desc&size=1\"\n",
    "\n",
    "    url1 = f\"https://api.pushshift.io/reddit/search/submission/?after={timestamp}&before={timestamp+86400}\"\n",
    "\n",
    "    # url = \"https://api.pushshift.io/reddit/submission/search/?after={timestamp}&before={timestamp+86400}&sort_type=score&sort=desc\"\n",
    "\n",
    "    print(url1)\n",
    "\n",
    "    response = requests.get(url1)\n",
    "\n",
    "    # Check if request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: API request failed with status code {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    # Extract data from response\n",
    "    data = response.json()[\"data\"]\n",
    "    if len(data) == 0:\n",
    "        print(f\"No posts found for {timestamp}\")\n",
    "        return None\n",
    "    \n",
    "    post = data[0]\n",
    "    subreddit = post[\"subreddit\"]\n",
    "    title = post[\"title\"]\n",
    "    score = post[\"score\"]\n",
    "    body = post[\"selftext\"]\n",
    "    \n",
    "    return {\"subreddit\": subreddit, \"title\": title, \"score\": score, \"body\": body}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1677398400\n",
      "1677484800\n",
      "https://api.pushshift.io/reddit/search/submission/?after=1677398400&before=1677484800\n",
      "{'subreddit': 'Pecs', 'title': \"let's get some!!\", 'score': 1, 'body': ''}\n"
     ]
    }
   ],
   "source": [
    "startTime = int(dt.datetime(2023,2,26,0,0).timestamp())\n",
    "print(startTime)\n",
    "print(startTime + 86400) \n",
    "print(get_most_popular_post_on_date(startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.pushshift.io/reddit/search/submission/?after=1582704000&before=1582790400\n",
      "No posts found for 1582704000\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(get_most_popular_post_on_date(int(dt.datetime(2020,2,26,0,0).timestamp())))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching posts found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# set the URL for the Pushshift API endpoint\n",
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "# set the parameters for the API request\n",
    "params = {\n",
    "    'subreddit': 'science',\n",
    "    'size': 1,\n",
    "    'sort': 'desc',\n",
    "    'after': '2020-01-01',\n",
    "    'before': '2023-02-01'\n",
    "}\n",
    "\n",
    "# send the API request and get the response\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# check if the 'data' key exists in the response\n",
    "if 'data' in data:\n",
    "    data = data['data']\n",
    "\n",
    "    # print the titles and comment counts of the top 10 posts\n",
    "    for post in data:\n",
    "        title = post['title']\n",
    "        num_comments = post['num_comments']\n",
    "        print(f'Title: {title}\\nNumber of comments: {num_comments}\\n')\n",
    "else:\n",
    "    print('No matching posts found.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most popular post Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_most_popular_post_on_date(date):\n",
    "    # Convert date to Unix timestamp\n",
    "    timestamp = int(dt.datetime.timestamp(date))\n",
    "    \n",
    "    # Make API request to get most popular post on date\n",
    "    url = f\"https://api.pushshift.io/reddit/search/submission/?after={timestamp}&before={timestamp+86400}&sort_type=score&sort=desc&size=1\"\n",
    "\n",
    "\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: API request failed with status code {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    # Extract data from response\n",
    "    data = response.json()[\"data\"]\n",
    "    if len(data) == 0:\n",
    "        print(f\"No posts found for {date}\")\n",
    "        return None\n",
    "    \n",
    "    post = data[0]\n",
    "    subreddit = post[\"subreddit\"]\n",
    "    title = post[\"title\"]\n",
    "    score = post[\"score\"]\n",
    "    body = post[\"selftext\"]\n",
    "    \n",
    "    return {\"subreddit\": subreddit, \"title\": title, \"score\": score, \"body\": body}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_popular_posts(start_date, end_date):\n",
    "    # Create list of dates to search for\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    dates = []\n",
    "    while start_date <= end_date:\n",
    "        dates.append(start_date)\n",
    "        start_date += delta\n",
    "    \n",
    "    # Get most popular post for each date\n",
    "    popular_posts = []\n",
    "    for date in dates:\n",
    "        post = get_most_popular_post_on_date(date)\n",
    "        if post:\n",
    "            popular_posts.append(post)\n",
    "    \n",
    "    return popular_posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: API request failed with status code 422\n",
      "Error: API request failed with status code 422\n",
      "Error: API request failed with status code 422\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/daniilabbruzzese/Documents/Senior Year/DSCI 550/DSCI550-PixstoryDataAnalysis/Daniil Code/Reddit_Data.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniilabbruzzese/Documents/Senior%20Year/DSCI%20550/DSCI550-PixstoryDataAnalysis/Daniil%20Code/Reddit_Data.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m start_date \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime(\u001b[39m2020\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniilabbruzzese/Documents/Senior%20Year/DSCI%20550/DSCI550-PixstoryDataAnalysis/Daniil%20Code/Reddit_Data.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m end_date \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime(\u001b[39m2021\u001b[39m, \u001b[39m12\u001b[39m, \u001b[39m31\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/daniilabbruzzese/Documents/Senior%20Year/DSCI%20550/DSCI550-PixstoryDataAnalysis/Daniil%20Code/Reddit_Data.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m popular_posts \u001b[39m=\u001b[39m get_popular_posts(start_date, end_date)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniilabbruzzese/Documents/Senior%20Year/DSCI%20550/DSCI550-PixstoryDataAnalysis/Daniil%20Code/Reddit_Data.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Print results\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniilabbruzzese/Documents/Senior%20Year/DSCI%20550/DSCI550-PixstoryDataAnalysis/Daniil%20Code/Reddit_Data.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m post \u001b[39min\u001b[39;00m popular_posts:\n",
      "\u001b[1;32m/Users/daniilabbruzzese/Documents/Senior Year/DSCI 550/DSCI550-PixstoryDataAnalysis/Daniil Code/Reddit_Data.ipynb Cell 7\u001b[0m in \u001b[0;36mget_popular_posts\u001b[0;34m(start_date, end_date)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniilabbruzzese/Documents/Senior%20Year/DSCI%20550/DSCI550-PixstoryDataAnalysis/Daniil%20Code/Reddit_Data.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m popular_posts \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniilabbruzzese/Documents/Senior%20Year/DSCI%20550/DSCI550-PixstoryDataAnalysis/Daniil%20Code/Reddit_Data.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m date \u001b[39min\u001b[39;00m dates:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/daniilabbruzzese/Documents/Senior%20Year/DSCI%20550/DSCI550-PixstoryDataAnalysis/Daniil%20Code/Reddit_Data.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     post \u001b[39m=\u001b[39m get_most_popular_post_on_date(date)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniilabbruzzese/Documents/Senior%20Year/DSCI%20550/DSCI550-PixstoryDataAnalysis/Daniil%20Code/Reddit_Data.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mif\u001b[39;00m post:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniilabbruzzese/Documents/Senior%20Year/DSCI%20550/DSCI550-PixstoryDataAnalysis/Daniil%20Code/Reddit_Data.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         popular_posts\u001b[39m.\u001b[39mappend(post)\n",
      "\u001b[1;32m/Users/daniilabbruzzese/Documents/Senior Year/DSCI 550/DSCI550-PixstoryDataAnalysis/Daniil Code/Reddit_Data.ipynb Cell 7\u001b[0m in \u001b[0;36mget_most_popular_post_on_date\u001b[0;34m(date)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniilabbruzzese/Documents/Senior%20Year/DSCI%20550/DSCI550-PixstoryDataAnalysis/Daniil%20Code/Reddit_Data.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Make API request to get most popular post on date\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniilabbruzzese/Documents/Senior%20Year/DSCI%20550/DSCI550-PixstoryDataAnalysis/Daniil%20Code/Reddit_Data.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://api.pushshift.io/reddit/search/submission/?after=\u001b[39m\u001b[39m{\u001b[39;00mtimestamp\u001b[39m}\u001b[39;00m\u001b[39m&before=\u001b[39m\u001b[39m{\u001b[39;00mtimestamp\u001b[39m+\u001b[39m\u001b[39m86400\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m&sort_type=score&sort=desc&size=1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/daniilabbruzzese/Documents/Senior%20Year/DSCI%20550/DSCI550-PixstoryDataAnalysis/Daniil%20Code/Reddit_Data.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniilabbruzzese/Documents/Senior%20Year/DSCI%20550/DSCI550-PixstoryDataAnalysis/Daniil%20Code/Reddit_Data.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Check if request was successful\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniilabbruzzese/Documents/Senior%20Year/DSCI%20550/DSCI550-PixstoryDataAnalysis/Daniil%20Code/Reddit_Data.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py:75\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     65\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m'\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    531\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:667\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[39mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    665\u001b[0m     \u001b[39m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m     gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolve_redirects(r, request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 667\u001b[0m     history \u001b[39m=\u001b[39m [resp \u001b[39mfor\u001b[39;00m resp \u001b[39min\u001b[39;00m gen]\n\u001b[1;32m    668\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    669\u001b[0m     history \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:667\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[39mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    665\u001b[0m     \u001b[39m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m     gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolve_redirects(r, request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 667\u001b[0m     history \u001b[39m=\u001b[39m [resp \u001b[39mfor\u001b[39;00m resp \u001b[39min\u001b[39;00m gen]\n\u001b[1;32m    668\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    669\u001b[0m     history \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:237\u001b[0m, in \u001b[0;36mSessionRedirectMixin.resolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39myield\u001b[39;00m req\n\u001b[1;32m    235\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    238\u001b[0m         req,\n\u001b[1;32m    239\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    240\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    241\u001b[0m         verify\u001b[39m=\u001b[39;49mverify,\n\u001b[1;32m    242\u001b[0m         cert\u001b[39m=\u001b[39;49mcert,\n\u001b[1;32m    243\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    244\u001b[0m         allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    245\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49madapter_kwargs\n\u001b[1;32m    246\u001b[0m     )\n\u001b[1;32m    248\u001b[0m     extract_cookies_to_jar(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcookies, prepared_request, resp\u001b[39m.\u001b[39mraw)\n\u001b[1;32m    250\u001b[0m     \u001b[39m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    644\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    647\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    648\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 440\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    441\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    442\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    443\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    444\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    445\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    446\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    447\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    448\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    449\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    450\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    451\u001b[0m         )\n\u001b[1;32m    453\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m'\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1378\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_date = datetime.datetime(2020, 1, 1)\n",
    "end_date = datetime.datetime(2021, 12, 31)\n",
    "popular_posts = get_popular_posts(start_date, end_date)\n",
    "\n",
    "# Print results\n",
    "for post in popular_posts:\n",
    "    print(post[\"subreddit\"])\n",
    "    print(post[\"title\"])\n",
    "    print(post[\"score\"])\n",
    "    print(post[\"body\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the API endpoint URL and parameters\n",
    "url = 'https://api.pushshift.io/reddit/search/comment'\n",
    "\n",
    "fields = ['author', 'body', 'created_utc']\n",
    "# Join the fields together with commas to create a string\n",
    "fields_string = ','.join(fields)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'subreddit': subreddit,\n",
    "    'size': 100,\n",
    "    'fields': fields,\n",
    "    'after': start_date,\n",
    "    'before': end_date\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to reddit_comments.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Send a GET request to the API endpoint with the specified parameters\n",
    "response = requests.get(url, params = params)\n",
    "\n",
    "# If the response was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Convert the response JSON string to a Python dictionary\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract the comments from the data dictionary\n",
    "    comments = data['data']\n",
    "   \n",
    "    filtered_comments = [{key: comment[key] for key in ['author', 'body', 'created_utc','score']} for comment in comments]\n",
    "\n",
    "    \n",
    "    # Write the comments data to a JSON file\n",
    "    with open('reddit_comments.json', 'w') as f:\n",
    "        json.dump(filtered_comments, f)\n",
    "    \n",
    "    # Print a success message\n",
    "    print('Data saved to reddit_comments.json')\n",
    "    \n",
    "else:\n",
    "    # If the response was not successful, print the status code\n",
    "    print(f'Request failed with status code {response.status_code}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you!</td>\n",
       "      <td>detarintehelavarlden</td>\n",
       "      <td>1614326158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you. I tried this, and yes, that numpy s...</td>\n",
       "      <td>detarintehelavarlden</td>\n",
       "      <td>1614326144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone here summarized it really well</td>\n",
       "      <td>Scetric</td>\n",
       "      <td>1614326121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The only way to transfer files between a Pi an...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1614326116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanks!</td>\n",
       "      <td>Scetric</td>\n",
       "      <td>1614326104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>One: definitely no need to be sorry, I think y...</td>\n",
       "      <td>Ok-Design-3218</td>\n",
       "      <td>1614319274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>I think you are looking for a priority queue. ...</td>\n",
       "      <td>schfourteen-teen</td>\n",
       "      <td>1614319240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A bit of modification to ur code works for me ...</td>\n",
       "      <td>ScarAlert</td>\n",
       "      <td>1614319235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>I used pip3 install pandas. I'm running Big Su...</td>\n",
       "      <td>KlontZ</td>\n",
       "      <td>1614318749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>for anyone that doesn't know, run\\n\\n`import t...</td>\n",
       "      <td>spez_edits_thedonald</td>\n",
       "      <td>1614318674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body                author  \\\n",
       "0                                          Thank you!  detarintehelavarlden   \n",
       "1   Thank you. I tried this, and yes, that numpy s...  detarintehelavarlden   \n",
       "2              Someone here summarized it really well               Scetric   \n",
       "3   The only way to transfer files between a Pi an...             [deleted]   \n",
       "4                                             Thanks!               Scetric   \n",
       "..                                                ...                   ...   \n",
       "95  One: definitely no need to be sorry, I think y...        Ok-Design-3218   \n",
       "96  I think you are looking for a priority queue. ...      schfourteen-teen   \n",
       "97  A bit of modification to ur code works for me ...             ScarAlert   \n",
       "98  I used pip3 install pandas. I'm running Big Su...                KlontZ   \n",
       "99  for anyone that doesn't know, run\\n\\n`import t...  spez_edits_thedonald   \n",
       "\n",
       "          date  \n",
       "0   1614326158  \n",
       "1   1614326144  \n",
       "2   1614326121  \n",
       "3   1614326116  \n",
       "4   1614326104  \n",
       "..         ...  \n",
       "95  1614319274  \n",
       "96  1614319240  \n",
       "97  1614319235  \n",
       "98  1614318749  \n",
       "99  1614318674  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Send a GET request to the API endpoint with the specified parameters\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# If the response was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Convert the response JSON string to a Python dictionary\n",
    "    data = json.loads(response.text)\n",
    "    \n",
    "    # Extract the comments from the data dictionary\n",
    "    comments = data['data']\n",
    "    \n",
    "    # Create a list of dictionaries representing the comments\n",
    "    comment_dicts = [{'body': comment['body'], 'author': comment['author'], 'date': comment['created_utc']} for comment in comments]\n",
    "    \n",
    "    # Convert the list of dictionaries to a Pandas dataframe\n",
    "    df = pd.DataFrame(comment_dicts)\n",
    "    \n",
    "    # Print the dataframe\n",
    "    #print(df)\n",
    "    \n",
    "else:\n",
    "    # If the response was not successful, print the status code\n",
    "    print(f'Request failed with status code {response.status_code}')\n",
    "\n",
    "\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14b5f4a1e35b3543103fc71a08ac87c31dbc262e66f163b05b7ba3f77eb1e8a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
