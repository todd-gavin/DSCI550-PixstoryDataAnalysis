{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tika Instructions\n",
    "- DONE - first, git clone http://github.com/chrismattmann/tika-similarity.git and then git clone http://github.com/chrismattmann/etllib.git You will use ETLlib for tsv2json\n",
    "\n",
    "- DONE - then cd tika-similarity and then inside there, do pip install -r requirements.txt . This will take care of installing Tika Similarity's dependencies. \n",
    "\n",
    "- DONE - Then inside of etllib do python setup.py install that will install the associated scripts like tsv2json etc (\n",
    "\n",
    "- make sure that you already have your dataset by this point, with all of your additional features added\n",
    "\n",
    "- then run tsv2json and generate approx 95k JSON files in a directory \n",
    "\n",
    "- once the files are generated in there, you can run similarity.py on the directory with the 95k JSON files\n",
    "\n",
    "- it will generate a file called similarity-scores.txt that has all the resemblance and pairwise similarity scores for each item in your posts with the additional features\n",
    "\n",
    "- then you should run cluster-json.py that will read the similarity-scores.txt and from there use the associated threshold to perform hierarchical agglomerative clustering and to generate clusters.json once you have that file generated you can browse the clusters\n",
    "\n",
    "- you can mess around with different metrics, e.g., try the edit distance version of similarity.py or use value versus key based similarity and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Metrics\n",
    "\n",
    "- Jaccard similarity: The ratio of the number of common elements between the sets to the total number of distinct elements in both sets. The Jaccard similarity coefficient can range from 0 to 1, where a value of 0 means that the two sets have no elements in common, and a value of 1 means that the two sets are identical.\n",
    "    - example: A = {1, 2, 3, 4, 5} B = {3, 4, 5, 6, 7}\n",
    "    - common elements = 3; {3, 4, 5}\n",
    "    - distinct elements = 7; {1, 2, 3, 4, 5, 6, 7}\n",
    "    - The Jaccard similarity coefficient --> J(A, B) = |A ∩ B| / |A ∪ B| = 3 / 7 = 0.43\n",
    "\n",
    "    \n",
    "\n",
    "- edit distance: the minimum number of insertions, deletions, and substitutions required to transform one string into another.\n",
    "    - For example, consider the strings \"cat\" and \"cut\". The edit distance between these two strings is 1, because we can transform \"cat\" into \"cut\" by substituting the \"a\" with a \"u\".\n",
    "\n",
    "- cosine similarity: compare the similarity of two documents or sentences represented as vectors of word frequencies. It measures the similarity between two vectors in a multi-dimensional space by taking the cosine of the angle between the vectors\n",
    "    - The resulting value ranges from -1 to 1, where -1 indicates that the two vectors are completely dissimilar, 0 indicates that they are orthogonal (i.e., perpendicular to each other), and 1 indicates that they are identical.\n",
    "    - ex: Sentence1: \"The cat sat on the mat\" ; Sentence2: \"The dog chased the cat off the mat\"\n",
    "    - unique words: [\"the\", \"cat\", \"sat\", \"on\", \"mat\", \"dog\", \"chased\", \"off\"]\n",
    "    - Vectors: Sentence1: [2, 1, 1, 1, 2, 1, 0, 0, 0], Sentence2: [3, 1, 0, 0, 1, 1, 1, 1, 1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import subprocess\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create TSV File\n",
    "with open('../Master Datasets/final_dataset.csv', 'r') as csv_file, open('../Master Datasets/Master_Dataset.tsv', 'w') as tsv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    tsv_writer = csv.writer(tsv_file, delimiter='\\t')\n",
    "    for row in csv_reader:\n",
    "        tsv_writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create headers text file from the tsv\n",
    "\n",
    "# Set the path to your TSV file and column headers file\n",
    "tsv_file_path = \"../Master Datasets/Master_Dataset.tsv\"\n",
    "column_headers_file_path = \"column_headers.txt\"\n",
    "\n",
    "# Open the TSV file and read the column headers\n",
    "with open(tsv_file_path, \"r\", encoding=\"utf-8\") as tsv_file:\n",
    "    reader = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "    headers = next(reader)\n",
    "    \n",
    "# Write the column headers to the text file\n",
    "with open(column_headers_file_path, \"w\", encoding=\"utf-8\") as headers_file:\n",
    "    for header in headers:\n",
    "        # Add a colon to the end of the header name if it's optional\n",
    "        if header.endswith(\":\"):\n",
    "            header = header[:-1] + \":\"\n",
    "        # Add an asterisk to the end of the header name if it's used for an ID field\n",
    "        elif header.endswith(\"*\"):\n",
    "            header = header[:-1] + \"*\"\n",
    "        headers_file.write(header + \"\\n\")\n",
    "\n",
    "\n",
    "#change date to dte\n",
    "\n",
    "\n",
    "# Open the file for reading\n",
    "with open('column_headers.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Replace \"Date\" with \"Dte\" using regular expressions\n",
    "content = re.sub(r'\\bAccount Created Date\\b', 'Dte', content)\n",
    "\n",
    "# Replace \"Date\" with \"Dte\" using regular expressions\n",
    "content = re.sub(r'\\bDate\\b', 'Dte', content)\n",
    "\n",
    "# Open the file for writing and overwrite the original content\n",
    "with open('column_headers.txt', 'w') as file:\n",
    "    file.write(content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#command to run tsvtojson\n",
    "\n",
    "\n",
    "python etllib/etl/tsvtojson.py -t Master_Dataset.tsv -j test3json.json -c column_headers.txt -o json_object -s 0.5\n",
    "\n",
    "#repackge json\n",
    "\n",
    "python etllib/etl/repackage.py -j test3json.json -o json_object -v\n",
    "\n",
    "#move to different folder called \"json_folder\"\n",
    "\n",
    "find . -name \"*.json\" -print0 | xargs -0 -I {} mv {} ./json_folder/\n",
    "\n",
    "#running similarity.py\n",
    "\n",
    "python tika-similarity/similarity.py -f 95kJSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting 95kJSON into 100 file chunks\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set the path to the directory containing the JSON files\n",
    "dir_path = \"95kJSON\"\n",
    "\n",
    "# Create a new subdirectory for the files\n",
    "sub_dir = 1\n",
    "os.makedirs(os.path.join(dir_path, \"subdir_{}\".format(sub_dir)), exist_ok=True)\n",
    "\n",
    "# Iterate through the JSON files in the directory\n",
    "count = 0\n",
    "for file_name in os.listdir(dir_path):\n",
    "    if file_name.endswith(\".json\"):\n",
    "        file_path = os.path.join(dir_path, file_name)\n",
    "        # Move the file to the current subdirectory\n",
    "        shutil.move(file_path, os.path.join(dir_path, \"subdir_{}\".format(sub_dir)))\n",
    "        count += 1\n",
    "        # If the current subdirectory contains 100 files, create a new one\n",
    "        if count == 100:\n",
    "            sub_dir += 1\n",
    "            os.makedirs(os.path.join(dir_path, \"subdir_{}\".format(sub_dir)), exist_ok=True)\n",
    "            count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jaccard similarity\n",
    "\n",
    "python tika-similarity/jaccard_similarity.py --inputDir 95kJSON/subdir_1 --outCSV jaccard1.csv\n",
    "\n",
    "#getting this error after running on python 2.7:     raise RuntimeError(\"Unable to start Tika server.\") RuntimeError: Unable to start Tika server.(python2_7) Daniils-MBP:Tika Analysis daniilabbruzzese$ \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.18 ('python2_7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42500a3a7309cf21444c568f4f87822c88175101a2a37dc5fe199abe6d99c65d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
