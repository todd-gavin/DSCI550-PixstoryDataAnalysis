{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# `Associated Sports Events Feature`\n",
    "This Jupyter Notebook will be used to parse the webpages and add data to the column in the master dataset which mentions related sports event based on date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Here we define a few functions, parse_link parses the webpages for the sports events tables, and saves those tables in the raw_files folder. The parse_dates function parses the string dates and converts them into date time objects showing the start and end datetime of a particular sports event. Finally, the save_formatted_sports_events_table brings both of these functions together and saves the formatted version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_link(url, year):\n",
    "    # make a request to the webpage\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # parse the HTML content using Beautiful Soup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # find the table containing the events\n",
    "    table = soup.find('table', {'class': 'list'})\n",
    "\n",
    "    # find all the rows in the table\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    # create a CSV file to write the scraped data\n",
    "    with open(f'raw_files/events_{year}.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        # write the table headers to the CSV file\n",
    "        headers = [th.text.strip() for th in rows[0].find_all('th')]\n",
    "        writer.writerow(headers)\n",
    "\n",
    "        # write the table rows to the CSV file, filtering out rows containing \"postponed\" or \"canceled\"\n",
    "        for row in rows[1:]:\n",
    "            data = [td.text.strip() for td in row.find_all('td')]\n",
    "            data = [x.replace('posponed', \"postponed\") for x in data]\n",
    "            data = [x.replace('postoned', \"postponed\") for x in data]\n",
    "\n",
    "            if 'postponed from' in data[0].lower():\n",
    "                writer.writerow(data)\n",
    "            elif 'canceled' in data[0].lower() or 'postponed' in data[0].lower():\n",
    "                continue\n",
    "            else:\n",
    "                writer.writerow(data)\n",
    "\n",
    "\n",
    "def parse_dates(date_str, year):\n",
    "    date_str = date_str.split(' (')[0]\n",
    "    date_str = date_str.replace('July', 'Jul')\n",
    "    date_str = date_str.replace('June', 'Jun')\n",
    "    date_str = date_str.replace('Sept', 'Sep')\n",
    "    date_str = date_str.replace('‚Äì', '-')\n",
    "    date_str = date_str.replace('8 Mar', 'Mar 8')\n",
    "    date_str = date_str.replace('1 Mar', 'Mar 1')\n",
    "\n",
    "    # split date range into start and end dates\n",
    "    date_range = date_str.split('-')\n",
    "\n",
    "    date_range = [x.strip() for x in date_range]\n",
    "\n",
    "    if len(date_range) == 1:\n",
    "        # if there is only one date, it is both the start and end date\n",
    "        date_start = datetime.strptime(date_range[0] + f' {year}', '%b %d %Y')\n",
    "        date_end = date_start\n",
    "    else:\n",
    "        # if second value can be converted to int, this is an individual month\n",
    "        if len(date_range[-1]) <= 2:\n",
    "            date_start = datetime.strptime(date_range[0] + f' {year}', '%b %d %Y')\n",
    "            date_end = datetime(int(year), date_start.month, int(date_range[-1]))\n",
    "        else:\n",
    "            # otherwise, parse both start and end dates\n",
    "            date_start = datetime.strptime(date_range[0] + f' {year}', '%b %d %Y')\n",
    "            date_end = datetime.strptime(date_range[1] + f' {year}', '%b %d %Y')\n",
    "\n",
    "    return date_start, date_end\n",
    "\n",
    "def save_formatted_sports_events_table(url, year):\n",
    "    parse_link(url, year)\n",
    "    save_filename = f\"raw_files/events_{year}.csv\"\n",
    "    df = pd.read_csv(save_filename)\n",
    "    df['date_start'], df['date_end'] = zip(*df['Date(s)'].apply(parse_dates, year=year))\n",
    "    df.to_csv(save_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now that we have the functions, we iterate over the years 2020, 2021, and 2022 and save the tables. We then merge these tables into one df, and save that csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years = [2020, 2021, 2022]\n",
    "dfs = list()\n",
    "\n",
    "for year in years:\n",
    "    url = f'https://www.topendsports.com/events/calendar-{year}.htm'\n",
    "    save_formatted_sports_events_table(url, year)\n",
    "\n",
    "for year in years:\n",
    "    df = pd.read_csv(f\"raw_files/events_{year}.csv\")\n",
    "    dfs.append(df)\n",
    "\n",
    "total = pd.concat(dfs)\n",
    "total.drop(columns='Date(s)', inplace=True)\n",
    "total.to_csv('raw_files/sports_events.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We now have a fully merged csv with everything we need. We need to convert this into a df which has dates ranging from Jan 1st 2020 to Dec 31st 2022, which we will further merge with our master dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"raw_files/sports_events.csv\")\n",
    "# convert start and end times to datetime\n",
    "df['date_start'] = pd.to_datetime(df['date_start'])\n",
    "df['date_end'] = pd.to_datetime(df['date_end'])\n",
    "\n",
    "# create a range of dates from Jan 1, 2020 to Dec 31, 2022\n",
    "dates = pd.date_range(start='2020-01-01', end='2022-12-31')\n",
    "\n",
    "# create an empty dataframe to store the results\n",
    "result = pd.DataFrame(columns=['Date', 'Event'])\n",
    "\n",
    "# iterate over each date and find the events that occurred on that date\n",
    "for date in dates:\n",
    "    events = df.loc[(df['date_start'] <= date) & (df['date_end'] >= date), 'Event'].tolist()\n",
    "    event_str = ', '.join(events)\n",
    "    result = result.append({'Date': date, 'Event': event_str}, ignore_index=True)\n",
    "\n",
    "# print the resulting dataframe\n",
    "result.to_csv(\"sports_events_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We got our df to merge. We finally perform the merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Story Primary ID</th>\n",
       "      <th>Story ID</th>\n",
       "      <th>User Primary ID</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Media</th>\n",
       "      <th>Account Created Date</th>\n",
       "      <th>Date (No Timestamp)</th>\n",
       "      <th>Interest</th>\n",
       "      <th>Sports Events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121169</td>\n",
       "      <td>STY1659426957</td>\n",
       "      <td>103</td>\n",
       "      <td>USR1606807023</td>\n",
       "      <td>female</td>\n",
       "      <td>34</td>\n",
       "      <td>Trend of the Year: Barbiecore</td>\n",
       "      <td>The colour of the year is here, and it's *drum...</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1659...</td>\n",
       "      <td>2020-01-12 12:47:00</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>trends, fashion, barbie</td>\n",
       "      <td>Winter Youth Olympics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127727</td>\n",
       "      <td>STY1660634861</td>\n",
       "      <td>103</td>\n",
       "      <td>USR1606807023</td>\n",
       "      <td>female</td>\n",
       "      <td>34</td>\n",
       "      <td>Abomination of the day</td>\n",
       "      <td>We Indians do love to bastardise our foods- Ch...</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1660...</td>\n",
       "      <td>2020-01-12 12:47:00</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>Food, momos, weird menus</td>\n",
       "      <td>Winter Youth Olympics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123665</td>\n",
       "      <td>STY1660027898</td>\n",
       "      <td>103</td>\n",
       "      <td>USR1606807023</td>\n",
       "      <td>female</td>\n",
       "      <td>34</td>\n",
       "      <td>Shameful headline in 2022</td>\n",
       "      <td>Can professors not have personal lives? \\n\\nAd...</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1660...</td>\n",
       "      <td>2020-01-12 12:47:00</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>misogyny, st  xaviers</td>\n",
       "      <td>Winter Youth Olympics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130517</td>\n",
       "      <td>STY1661151635</td>\n",
       "      <td>103</td>\n",
       "      <td>USR1606807023</td>\n",
       "      <td>female</td>\n",
       "      <td>34</td>\n",
       "      <td>Woman lawyer arrested for abusing security guard</td>\n",
       "      <td>She was recorded on video manhandling him, sho...</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1661...</td>\n",
       "      <td>2020-01-12 12:47:00</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>Technology, History, Food, Entertainment, Spor...</td>\n",
       "      <td>Winter Youth Olympics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125466</td>\n",
       "      <td>STY1660372361</td>\n",
       "      <td>109</td>\n",
       "      <td>USR1606851217</td>\n",
       "      <td>others</td>\n",
       "      <td>31</td>\n",
       "      <td>What is the Inflation Reduction Act?</td>\n",
       "      <td>The House passed the Inflation Reduction Act o...</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1660...</td>\n",
       "      <td>2020-02-12 01:03:00</td>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>us government</td>\n",
       "      <td>Six Nations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94995</th>\n",
       "      <td>125349</td>\n",
       "      <td>STY1660325841</td>\n",
       "      <td>71665</td>\n",
       "      <td>USR1660325291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>COLLEGE LIFE</td>\n",
       "      <td>MODR CLASS</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1660...</td>\n",
       "      <td>2022-12-08 22:58:00</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>college life, college life umang</td>\n",
       "      <td>FIFA World Cup, World Championships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94996</th>\n",
       "      <td>125345</td>\n",
       "      <td>STY1660325638</td>\n",
       "      <td>71673</td>\n",
       "      <td>USR1660325486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>The one with the bestieüòç</td>\n",
       "      <td>College life without a friend is useless. Enjo...</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1660...</td>\n",
       "      <td>2022-12-08 23:01:00</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>college life</td>\n",
       "      <td>FIFA World Cup, World Championships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94997</th>\n",
       "      <td>125355</td>\n",
       "      <td>STY1660326971</td>\n",
       "      <td>71697</td>\n",
       "      <td>USR1660326022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>College</td>\n",
       "      <td>Sheridan college, HazelMcCallion Canpus</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1660...</td>\n",
       "      <td>2022-12-08 23:10:00</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>college life, college life umang</td>\n",
       "      <td>FIFA World Cup, World Championships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94998</th>\n",
       "      <td>125351</td>\n",
       "      <td>STY1660326276</td>\n",
       "      <td>71698</td>\n",
       "      <td>USR1660326026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>A tale of friendship</td>\n",
       "      <td>Check this out.</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1660...</td>\n",
       "      <td>2022-12-08 23:10:00</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>friends</td>\n",
       "      <td>FIFA World Cup, World Championships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94999</th>\n",
       "      <td>125354</td>\n",
       "      <td>STY1660326403</td>\n",
       "      <td>71708</td>\n",
       "      <td>USR1660326251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>The mandatory mirror selfie</td>\n",
       "      <td>Spending time in college with these two maddie...</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1660...</td>\n",
       "      <td>2022-12-08 23:14:00</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>college life</td>\n",
       "      <td>FIFA World Cup, World Championships</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95000 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Story Primary ID       Story ID  User Primary ID        User ID  \\\n",
       "0                121169  STY1659426957              103  USR1606807023   \n",
       "1                127727  STY1660634861              103  USR1606807023   \n",
       "2                123665  STY1660027898              103  USR1606807023   \n",
       "3                130517  STY1661151635              103  USR1606807023   \n",
       "4                125466  STY1660372361              109  USR1606851217   \n",
       "...                 ...            ...              ...            ...   \n",
       "94995            125349  STY1660325841            71665  USR1660325291   \n",
       "94996            125345  STY1660325638            71673  USR1660325486   \n",
       "94997            125355  STY1660326971            71697  USR1660326022   \n",
       "94998            125351  STY1660326276            71698  USR1660326026   \n",
       "94999            125354  STY1660326403            71708  USR1660326251   \n",
       "\n",
       "       Gender  Age                                             Title  \\\n",
       "0      female   34                     Trend of the Year: Barbiecore   \n",
       "1      female   34                            Abomination of the day   \n",
       "2      female   34                         Shameful headline in 2022   \n",
       "3      female   34  Woman lawyer arrested for abusing security guard   \n",
       "4      others   31              What is the Inflation Reduction Act?   \n",
       "...       ...  ...                                               ...   \n",
       "94995     NaN   18                                      COLLEGE LIFE   \n",
       "94996     NaN   17                          The one with the bestieüòç   \n",
       "94997     NaN   19                                           College   \n",
       "94998     NaN   21                              A tale of friendship   \n",
       "94999     NaN   17                       The mandatory mirror selfie   \n",
       "\n",
       "                                               Narrative  \\\n",
       "0      The colour of the year is here, and it's *drum...   \n",
       "1      We Indians do love to bastardise our foods- Ch...   \n",
       "2      Can professors not have personal lives? \\n\\nAd...   \n",
       "3      She was recorded on video manhandling him, sho...   \n",
       "4      The House passed the Inflation Reduction Act o...   \n",
       "...                                                  ...   \n",
       "94995                                         MODR CLASS   \n",
       "94996  College life without a friend is useless. Enjo...   \n",
       "94997            Sheridan college, HazelMcCallion Canpus   \n",
       "94998                                    Check this out.   \n",
       "94999  Spending time in college with these two maddie...   \n",
       "\n",
       "                                                   Media Account Created Date  \\\n",
       "0      https://image.pixstory.com/Pixstory-image-1659...  2020-01-12 12:47:00   \n",
       "1      https://image.pixstory.com/Pixstory-image-1660...  2020-01-12 12:47:00   \n",
       "2      https://image.pixstory.com/Pixstory-image-1660...  2020-01-12 12:47:00   \n",
       "3      https://image.pixstory.com/Pixstory-image-1661...  2020-01-12 12:47:00   \n",
       "4      https://image.pixstory.com/Pixstory-image-1660...  2020-02-12 01:03:00   \n",
       "...                                                  ...                  ...   \n",
       "94995  https://image.pixstory.com/Pixstory-image-1660...  2022-12-08 22:58:00   \n",
       "94996  https://image.pixstory.com/Pixstory-image-1660...  2022-12-08 23:01:00   \n",
       "94997  https://image.pixstory.com/Pixstory-image-1660...  2022-12-08 23:10:00   \n",
       "94998  https://image.pixstory.com/Pixstory-image-1660...  2022-12-08 23:10:00   \n",
       "94999  https://image.pixstory.com/Pixstory-image-1660...  2022-12-08 23:14:00   \n",
       "\n",
       "      Date (No Timestamp)                                           Interest  \\\n",
       "0              2020-01-12                            trends, fashion, barbie   \n",
       "1              2020-01-12                           Food, momos, weird menus   \n",
       "2              2020-01-12                              misogyny, st  xaviers   \n",
       "3              2020-01-12  Technology, History, Food, Entertainment, Spor...   \n",
       "4              2020-02-12                                      us government   \n",
       "...                   ...                                                ...   \n",
       "94995          2022-12-08                   college life, college life umang   \n",
       "94996          2022-12-08                                       college life   \n",
       "94997          2022-12-08                   college life, college life umang   \n",
       "94998          2022-12-08                                            friends   \n",
       "94999          2022-12-08                                       college life   \n",
       "\n",
       "                             Sports Events  \n",
       "0                    Winter Youth Olympics  \n",
       "1                    Winter Youth Olympics  \n",
       "2                    Winter Youth Olympics  \n",
       "3                    Winter Youth Olympics  \n",
       "4                              Six Nations  \n",
       "...                                    ...  \n",
       "94995  FIFA World Cup, World Championships  \n",
       "94996  FIFA World Cup, World Championships  \n",
       "94997  FIFA World Cup, World Championships  \n",
       "94998  FIFA World Cup, World Championships  \n",
       "94999  FIFA World Cup, World Championships  \n",
       "\n",
       "[95000 rows x 13 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('../Master Datasets/Master_Dataset_Raw.csv')\n",
    "df2 = pd.read_csv(\"sports_events_final.csv\")\n",
    "\n",
    "og_dates = df1['Account Created Date']\n",
    "\n",
    "# Convert \"Account Created Date\" column in df1 to datetime\n",
    "df1['Account Created Date'] = pd.to_datetime(df1['Account Created Date'])\n",
    "\n",
    "# Convert \"Date\" column in df2 to datetime\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "\n",
    "# merge the two dataframes based on the dates\n",
    "merged_df = pd.merge(df1, df2[['Date', 'Event']], how='left', left_on=df1['Account Created Date'].dt.date, right_on=df2['Date'].dt.date)\n",
    "\n",
    "# drop the duplicate date column\n",
    "merged_df = merged_df.drop('key_0', axis=1)\n",
    "\n",
    "# rename the 'Event' column to 'Events'\n",
    "merged_df = merged_df.rename(columns={'Event': 'Events'})\n",
    "\n",
    "# set the 'Events' column to NaN where there is no matching date\n",
    "merged_df.loc[merged_df['Events'].isna(), 'Events'] = ''\n",
    "\n",
    "# drop the duplicate date column\n",
    "merged_df = merged_df.drop('Date', axis=1)\n",
    "\n",
    "merged_df = merged_df.rename(columns={'Events': 'Sports Events'})\n",
    "\n",
    "# display the resulting dataframe\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('../Master Datasets/Master_Dataset_Raw_SportsEvents.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
