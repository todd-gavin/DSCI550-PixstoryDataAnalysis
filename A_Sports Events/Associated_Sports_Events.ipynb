{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Associated Sports Events Column\n",
    "This Jupyter Notebook will be used to parse the webpages and add data to the column in the master dataset which mentions related sports event based on date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Here we define a few functions, parse_link parses the webpages for the sports events tables, and saves those tables in the raw_files folder. The parse_dates function parses the string dates and converts them into date time objects showing the start and end datetime of a particular sports event. Finally, the save_formatted_sports_events_table brings both of these functions together and saves the formatted version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_link(url, year):\n",
    "    # make a request to the webpage\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # parse the HTML content using Beautiful Soup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # find the table containing the events\n",
    "    table = soup.find('table', {'class': 'list'})\n",
    "\n",
    "    # find all the rows in the table\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    # create a CSV file to write the scraped data\n",
    "    with open(f'raw_files/events_{year}.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        # write the table headers to the CSV file\n",
    "        headers = [th.text.strip() for th in rows[0].find_all('th')]\n",
    "        writer.writerow(headers)\n",
    "\n",
    "        # write the table rows to the CSV file, filtering out rows containing \"postponed\" or \"canceled\"\n",
    "        for row in rows[1:]:\n",
    "            data = [td.text.strip() for td in row.find_all('td')]\n",
    "            data = [x.replace('posponed', \"postponed\") for x in data]\n",
    "            data = [x.replace('postoned', \"postponed\") for x in data]\n",
    "\n",
    "            if 'postponed from' in data[0].lower():\n",
    "                writer.writerow(data)\n",
    "            elif 'canceled' in data[0].lower() or 'postponed' in data[0].lower():\n",
    "                continue\n",
    "            else:\n",
    "                writer.writerow(data)\n",
    "\n",
    "\n",
    "def parse_dates(date_str, year):\n",
    "    date_str = date_str.split(' (')[0]\n",
    "    date_str = date_str.replace('July', 'Jul')\n",
    "    date_str = date_str.replace('June', 'Jun')\n",
    "    date_str = date_str.replace('Sept', 'Sep')\n",
    "    date_str = date_str.replace('–', '-')\n",
    "    date_str = date_str.replace('8 Mar', 'Mar 8')\n",
    "    date_str = date_str.replace('1 Mar', 'Mar 1')\n",
    "\n",
    "    # split date range into start and end dates\n",
    "    date_range = date_str.split('-')\n",
    "\n",
    "    date_range = [x.strip() for x in date_range]\n",
    "\n",
    "    if len(date_range) == 1:\n",
    "        # if there is only one date, it is both the start and end date\n",
    "        date_start = datetime.strptime(date_range[0] + f' {year}', '%b %d %Y')\n",
    "        date_end = date_start\n",
    "    else:\n",
    "        # if second value can be converted to int, this is an individual month\n",
    "        if len(date_range[-1]) <= 2:\n",
    "            date_start = datetime.strptime(date_range[0] + f' {year}', '%b %d %Y')\n",
    "            date_end = datetime(int(year), date_start.month, int(date_range[-1]))\n",
    "        else:\n",
    "            # otherwise, parse both start and end dates\n",
    "            date_start = datetime.strptime(date_range[0] + f' {year}', '%b %d %Y')\n",
    "            date_end = datetime.strptime(date_range[1] + f' {year}', '%b %d %Y')\n",
    "\n",
    "    return date_start, date_end\n",
    "\n",
    "def save_formatted_sports_events_table(url, year):\n",
    "    parse_link(url, year)\n",
    "    save_filename = f\"raw_files/events_{year}.csv\"\n",
    "    df = pd.read_csv(save_filename)\n",
    "    df['date_start'], df['date_end'] = zip(*df['Date(s)'].apply(parse_dates, year=year))\n",
    "    df.to_csv(save_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now that we have the functions, we iterate over the years 2020, 2021, and 2022 and save the tables. We then merge these tables into one df, and save that csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years = [2020, 2021, 2022]\n",
    "dfs = list()\n",
    "\n",
    "for year in years:\n",
    "    url = f'https://www.topendsports.com/events/calendar-{year}.htm'\n",
    "    save_formatted_sports_events_table(url, year)\n",
    "\n",
    "for year in years:\n",
    "    df = pd.read_csv(f\"raw_files/events_{year}.csv\")\n",
    "    dfs.append(df)\n",
    "\n",
    "total = pd.concat(dfs)\n",
    "total.drop(columns='Date(s)', inplace=True)\n",
    "total.to_csv('raw_files/sports_events.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We now have a fully merged csv with everything we need. We need to convert this into a df which has dates ranging from Jan 1st 2020 to Dec 31st 2022, which we will further merge with our master dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"raw_files/sports_events.csv\")\n",
    "# convert start and end times to datetime\n",
    "df['date_start'] = pd.to_datetime(df['date_start'])\n",
    "df['date_end'] = pd.to_datetime(df['date_end'])\n",
    "\n",
    "# create a range of dates from Jan 1, 2020 to Dec 31, 2022\n",
    "dates = pd.date_range(start='2020-01-01', end='2022-12-31')\n",
    "\n",
    "# create an empty dataframe to store the results\n",
    "result = pd.DataFrame(columns=['Date', 'Event'])\n",
    "\n",
    "# iterate over each date and find the events that occurred on that date\n",
    "for date in dates:\n",
    "    events = df.loc[(df['date_start'] <= date) & (df['date_end'] >= date), 'Event'].tolist()\n",
    "    event_str = ', '.join(events)\n",
    "    result = result.append({'Date': date, 'Event': event_str}, ignore_index=True)\n",
    "\n",
    "# print the resulting dataframe\n",
    "result.to_csv(\"sports_events_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We got our df to merge. We finally perform the merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Story Primary ID</th>\n",
       "      <th>Story ID</th>\n",
       "      <th>User Primary ID</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Media</th>\n",
       "      <th>Account Created Date</th>\n",
       "      <th>Date (No Timestamp)</th>\n",
       "      <th>Interest</th>\n",
       "      <th>Sports Events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120776</td>\n",
       "      <td>STY1659352850</td>\n",
       "      <td>310</td>\n",
       "      <td>USR1609427903</td>\n",
       "      <td>male</td>\n",
       "      <td>45</td>\n",
       "      <td>Interview with the Nobel laureate Sir Richard ...</td>\n",
       "      <td>My interview with the Nobel laureate Sir Richa...</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1659...</td>\n",
       "      <td>2020-12-31 20:48:00</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>science and technology</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127677</td>\n",
       "      <td>STY1660623694</td>\n",
       "      <td>310</td>\n",
       "      <td>USR1609427903</td>\n",
       "      <td>male</td>\n",
       "      <td>45</td>\n",
       "      <td>Participated in the historical Har Ghar Tirang...</td>\n",
       "      <td>'Har Ghar Tiranga’ is a campaign under the aeg...</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1660...</td>\n",
       "      <td>2020-12-31 20:48:00</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>nationalism</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123275</td>\n",
       "      <td>STY1659941140</td>\n",
       "      <td>8601</td>\n",
       "      <td>USR1630424770</td>\n",
       "      <td>others</td>\n",
       "      <td>13</td>\n",
       "      <td>8. Contemporary Afghanistan : Major Ethnic gro...</td>\n",
       "      <td>The Challenges to Nation-Building\\nin Afghanis...</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1630...</td>\n",
       "      <td>2021-08-31 21:16:00</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>contemporary afghanistan, books</td>\n",
       "      <td>Paralympic Games, US Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121532</td>\n",
       "      <td>STY1659512311</td>\n",
       "      <td>8601</td>\n",
       "      <td>USR1630424770</td>\n",
       "      <td>others</td>\n",
       "      <td>13</td>\n",
       "      <td>6. Contemporary Afghanistan : Gender roles wit...</td>\n",
       "      <td>The Challenges to Nation-Building\\nin Afghanis...</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1630...</td>\n",
       "      <td>2021-08-31 21:16:00</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>contemporary afghanistan, books</td>\n",
       "      <td>Paralympic Games, US Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121141</td>\n",
       "      <td>STY1659422889</td>\n",
       "      <td>8601</td>\n",
       "      <td>USR1630424770</td>\n",
       "      <td>others</td>\n",
       "      <td>13</td>\n",
       "      <td>5. Contemporary Afghanistan : The 'Afghan Pride'</td>\n",
       "      <td>The Challenges to Nation-Building\\nin Afghanis...</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1630...</td>\n",
       "      <td>2021-08-31 21:16:00</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>contemporary afghanistan, books</td>\n",
       "      <td>Paralympic Games, US Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94995</th>\n",
       "      <td>126771</td>\n",
       "      <td>STY1660496705</td>\n",
       "      <td>14847</td>\n",
       "      <td>USR1641042672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>Shared from Adya U Routray</td>\n",
       "      <td>Friendshipday'22</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1660...</td>\n",
       "      <td>2022-01-01 18:41:00</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>friendshipday22, friendshipday'22</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94996</th>\n",
       "      <td>126765</td>\n",
       "      <td>STY1660496512</td>\n",
       "      <td>14846</td>\n",
       "      <td>USR1641042530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>On-screen friendships</td>\n",
       "      <td>Indian show Panchayat.</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1660...</td>\n",
       "      <td>2022-01-01 18:38:00</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>friendshipday22</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94997</th>\n",
       "      <td>125347</td>\n",
       "      <td>STY1660325731</td>\n",
       "      <td>14837</td>\n",
       "      <td>USR1641025987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>Panchayat one of my fav show</td>\n",
       "      <td>Loved the friendship on the show</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1660...</td>\n",
       "      <td>2022-01-01 14:03:00</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>friendshipday22</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94998</th>\n",
       "      <td>125429</td>\n",
       "      <td>STY1660360677</td>\n",
       "      <td>14835</td>\n",
       "      <td>USR1641023505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>On-screen Bffs</td>\n",
       "      <td>Glad to read this.</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1660...</td>\n",
       "      <td>2022-01-01 13:21:00</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>friendshipday</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94999</th>\n",
       "      <td>124496</td>\n",
       "      <td>STY1660157368</td>\n",
       "      <td>14832</td>\n",
       "      <td>USR1641020470</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>\"Remember George, no man is a failure who has ...</td>\n",
       "      <td>(Favorite on-screen Bffs)\\nPop-culture time an...</td>\n",
       "      <td>https://image.pixstory.com/Pixstory-image-1660...</td>\n",
       "      <td>2022-01-01 12:31:00</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>friendshipday'22, friendshipday22</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Story Primary ID       Story ID  User Primary ID        User ID  \\\n",
       "0                120776  STY1659352850              310  USR1609427903   \n",
       "1                127677  STY1660623694              310  USR1609427903   \n",
       "2                123275  STY1659941140             8601  USR1630424770   \n",
       "3                121532  STY1659512311             8601  USR1630424770   \n",
       "4                121141  STY1659422889             8601  USR1630424770   \n",
       "...                 ...            ...              ...            ...   \n",
       "94995            126771  STY1660496705            14847  USR1641042672   \n",
       "94996            126765  STY1660496512            14846  USR1641042530   \n",
       "94997            125347  STY1660325731            14837  USR1641025987   \n",
       "94998            125429  STY1660360677            14835  USR1641023505   \n",
       "94999            124496  STY1660157368            14832  USR1641020470   \n",
       "\n",
       "       Gender  Age                                              Title  \\\n",
       "0        male   45  Interview with the Nobel laureate Sir Richard ...   \n",
       "1        male   45  Participated in the historical Har Ghar Tirang...   \n",
       "2      others   13  8. Contemporary Afghanistan : Major Ethnic gro...   \n",
       "3      others   13  6. Contemporary Afghanistan : Gender roles wit...   \n",
       "4      others   13   5. Contemporary Afghanistan : The 'Afghan Pride'   \n",
       "...       ...  ...                                                ...   \n",
       "94995     NaN   17                         Shared from Adya U Routray   \n",
       "94996     NaN   23                              On-screen friendships   \n",
       "94997     NaN   20                       Panchayat one of my fav show   \n",
       "94998     NaN   47                                     On-screen Bffs   \n",
       "94999  female   24  \"Remember George, no man is a failure who has ...   \n",
       "\n",
       "                                               Narrative  \\\n",
       "0      My interview with the Nobel laureate Sir Richa...   \n",
       "1      'Har Ghar Tiranga’ is a campaign under the aeg...   \n",
       "2      The Challenges to Nation-Building\\nin Afghanis...   \n",
       "3      The Challenges to Nation-Building\\nin Afghanis...   \n",
       "4      The Challenges to Nation-Building\\nin Afghanis...   \n",
       "...                                                  ...   \n",
       "94995                                   Friendshipday'22   \n",
       "94996                             Indian show Panchayat.   \n",
       "94997                   Loved the friendship on the show   \n",
       "94998                                 Glad to read this.   \n",
       "94999  (Favorite on-screen Bffs)\\nPop-culture time an...   \n",
       "\n",
       "                                                   Media Account Created Date  \\\n",
       "0      https://image.pixstory.com/Pixstory-image-1659...  2020-12-31 20:48:00   \n",
       "1      https://image.pixstory.com/Pixstory-image-1660...  2020-12-31 20:48:00   \n",
       "2      https://image.pixstory.com/Pixstory-image-1630...  2021-08-31 21:16:00   \n",
       "3      https://image.pixstory.com/Pixstory-image-1630...  2021-08-31 21:16:00   \n",
       "4      https://image.pixstory.com/Pixstory-image-1630...  2021-08-31 21:16:00   \n",
       "...                                                  ...                  ...   \n",
       "94995  https://image.pixstory.com/Pixstory-image-1660...  2022-01-01 18:41:00   \n",
       "94996  https://image.pixstory.com/Pixstory-image-1660...  2022-01-01 18:38:00   \n",
       "94997  https://image.pixstory.com/Pixstory-image-1660...  2022-01-01 14:03:00   \n",
       "94998  https://image.pixstory.com/Pixstory-image-1660...  2022-01-01 13:21:00   \n",
       "94999  https://image.pixstory.com/Pixstory-image-1660...  2022-01-01 12:31:00   \n",
       "\n",
       "      Date (No Timestamp)                           Interest  \\\n",
       "0              2020-12-31             science and technology   \n",
       "1              2020-12-31                        nationalism   \n",
       "2              2021-08-31    contemporary afghanistan, books   \n",
       "3              2021-08-31    contemporary afghanistan, books   \n",
       "4              2021-08-31    contemporary afghanistan, books   \n",
       "...                   ...                                ...   \n",
       "94995          2022-01-01  friendshipday22, friendshipday'22   \n",
       "94996          2022-01-01                    friendshipday22   \n",
       "94997          2022-01-01                    friendshipday22   \n",
       "94998          2022-01-01                      friendshipday   \n",
       "94999          2022-01-01  friendshipday'22, friendshipday22   \n",
       "\n",
       "                   Sports Events  \n",
       "0                                 \n",
       "1                                 \n",
       "2      Paralympic Games, US Open  \n",
       "3      Paralympic Games, US Open  \n",
       "4      Paralympic Games, US Open  \n",
       "...                          ...  \n",
       "94995                             \n",
       "94996                             \n",
       "94997                             \n",
       "94998                             \n",
       "94999                             \n",
       "\n",
       "[95000 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('../Master Datasets/Master_Dataset_Raw.csv')\n",
    "df2 = pd.read_csv(\"sports_events_final.csv\")\n",
    "\n",
    "og_dates = df1['Account Created Date']\n",
    "\n",
    "# Convert \"Account Created Date\" column in df1 to datetime\n",
    "df1['Account Created Date'] = pd.to_datetime(df1['Account Created Date'])\n",
    "\n",
    "# Convert \"Date\" column in df2 to datetime\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "\n",
    "# merge the two dataframes based on the dates\n",
    "merged_df = pd.merge(df1, df2[['Date', 'Event']], how='left', left_on=df1['Account Created Date'].dt.date, right_on=df2['Date'].dt.date)\n",
    "\n",
    "# drop the duplicate date column\n",
    "merged_df = merged_df.drop('key_0', axis=1)\n",
    "\n",
    "# rename the 'Event' column to 'Events'\n",
    "merged_df = merged_df.rename(columns={'Event': 'Events'})\n",
    "\n",
    "# set the 'Events' column to NaN where there is no matching date\n",
    "merged_df.loc[merged_df['Events'].isna(), 'Events'] = ''\n",
    "\n",
    "# drop the duplicate date column\n",
    "merged_df = merged_df.drop('Date', axis=1)\n",
    "\n",
    "merged_df = merged_df.rename(columns={'Events': 'Sports Events'})\n",
    "\n",
    "# display the resulting dataframe\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('../Master Datasets/Master_Dataset_Raw_SportsEvents.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
