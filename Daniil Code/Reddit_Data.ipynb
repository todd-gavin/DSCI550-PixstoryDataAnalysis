{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from psaw import PushshiftAPI                               #Importing wrapper library for reddit(Pushshift)\n",
    "import datetime as dt                                       #Importing library for date management\n",
    "import pandas as pd                                         #Importing library for data manipulation in python\n",
    "import matplotlib.pyplot as plt      \n",
    "import yfinance as yf                    #Importing library for creating interactive visualizations in Python\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import statsmodels.formula.api as smf\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = int(dt.datetime(2021,2,26,0,0).timestamp()) #.timestamp() converts the date to epoch time \n",
    "start_date = int(dt.datetime(2021,1,1,0,0).timestamp())\n",
    "subreddit = 'learnpython'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the API endpoint URL and parameters\n",
    "url = 'https://api.pushshift.io/reddit/search/comment'\n",
    "\n",
    "fields = ['author', 'body', 'created_utc']\n",
    "# Join the fields together with commas to create a string\n",
    "fields_string = ','.join(fields)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'subreddit': subreddit,\n",
    "    'size': 100,\n",
    "    'fields': fields,\n",
    "    'after': start_date,\n",
    "    'before': end_date\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to reddit_comments.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Send a GET request to the API endpoint with the specified parameters\n",
    "response = requests.get(url, params = params)\n",
    "\n",
    "# If the response was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Convert the response JSON string to a Python dictionary\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract the comments from the data dictionary\n",
    "    comments = data['data']\n",
    "   \n",
    "    filtered_comments = [{key: comment[key] for key in ['author', 'body', 'created_utc','score']} for comment in comments]\n",
    "\n",
    "    \n",
    "    # Write the comments data to a JSON file\n",
    "    with open('reddit_comments.json', 'w') as f:\n",
    "        json.dump(filtered_comments, f)\n",
    "    \n",
    "    # Print a success message\n",
    "    print('Data saved to reddit_comments.json')\n",
    "    \n",
    "else:\n",
    "    # If the response was not successful, print the status code\n",
    "    print(f'Request failed with status code {response.status_code}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I use Jupyter Labs in Anaconda. Jupyter Notebo...</td>\n",
       "      <td>paxfuturus</td>\n",
       "      <td>1677559378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The load() function requires parameter loader=...</td>\n",
       "      <td>eleqtriq</td>\n",
       "      <td>1677559037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VSCode runs on all platforms!</td>\n",
       "      <td>pixegami</td>\n",
       "      <td>1677559007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is the same as the reduce. The second param...</td>\n",
       "      <td>eplaut_</td>\n",
       "      <td>1677558420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ha it happens.</td>\n",
       "      <td>WhipsAndMarkovChains</td>\n",
       "      <td>1677558379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>decoded_word = 'LOOPS'\\n    \\n    for i in...</td>\n",
       "      <td>WhipsAndMarkovChains</td>\n",
       "      <td>1677558339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Didn't twitter shut down the api?</td>\n",
       "      <td>eleqtriq</td>\n",
       "      <td>1677558326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5: Use a library written in a faster language ...</td>\n",
       "      <td>smurpau2</td>\n",
       "      <td>1677558320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Oops you've beat me ðŸ¤ª</td>\n",
       "      <td>deep_politics</td>\n",
       "      <td>1677558295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Like this?\\n\\n```\\ncypher=\"text\"\\nfor i in ran...</td>\n",
       "      <td>eleqtriq</td>\n",
       "      <td>1677558270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body                author  \\\n",
       "0  I use Jupyter Labs in Anaconda. Jupyter Notebo...            paxfuturus   \n",
       "1  The load() function requires parameter loader=...              eleqtriq   \n",
       "2                      VSCode runs on all platforms!              pixegami   \n",
       "3  It is the same as the reduce. The second param...               eplaut_   \n",
       "4                                     Ha it happens.  WhipsAndMarkovChains   \n",
       "5      decoded_word = 'LOOPS'\\n    \\n    for i in...  WhipsAndMarkovChains   \n",
       "6                  Didn't twitter shut down the api?              eleqtriq   \n",
       "7  5: Use a library written in a faster language ...              smurpau2   \n",
       "8                              Oops you've beat me ðŸ¤ª         deep_politics   \n",
       "9  Like this?\\n\\n```\\ncypher=\"text\"\\nfor i in ran...              eleqtriq   \n",
       "\n",
       "         date  \n",
       "0  1677559378  \n",
       "1  1677559037  \n",
       "2  1677559007  \n",
       "3  1677558420  \n",
       "4  1677558379  \n",
       "5  1677558339  \n",
       "6  1677558326  \n",
       "7  1677558320  \n",
       "8  1677558295  \n",
       "9  1677558270  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Send a GET request to the API endpoint with the specified parameters\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# If the response was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Convert the response JSON string to a Python dictionary\n",
    "    data = json.loads(response.text)\n",
    "    \n",
    "    # Extract the comments from the data dictionary\n",
    "    comments = data['data']\n",
    "    \n",
    "    # Create a list of dictionaries representing the comments\n",
    "    comment_dicts = [{'body': comment['body'], 'author': comment['author'], 'date': comment['created_utc']} for comment in comments]\n",
    "    \n",
    "    # Convert the list of dictionaries to a Pandas dataframe\n",
    "    df = pd.DataFrame(comment_dicts)\n",
    "    \n",
    "    # Print the dataframe\n",
    "    #print(df)\n",
    "    \n",
    "else:\n",
    "    # If the response was not successful, print the status code\n",
    "    print(f'Request failed with status code {response.status_code}')\n",
    "\n",
    "\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14b5f4a1e35b3543103fc71a08ac87c31dbc262e66f163b05b7ba3f77eb1e8a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
